{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paperspace/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Train convolutional network for sentiment analysis on IMDB corpus. Based on\n",
    "\"Convolutional Neural Networks for Sentence Classification\" by Yoon Kim\n",
    "http://arxiv.org/pdf/1408.5882v2.pdf\n",
    "\n",
    "For \"CNN-rand\" and \"CNN-non-static\" gets to 88-90%, and \"CNN-static\" - 85% after 2-5 epochs with following settings:\n",
    "embedding_dim = 50          \n",
    "filter_sizes = (3, 8)\n",
    "num_filters = 10\n",
    "dropout_prob = (0.5, 0.8)\n",
    "hidden_dims = 50\n",
    "\n",
    "Differences from original article:\n",
    "- larger IMDB corpus, longer sentences; sentence length is very important, just like data size\n",
    "- smaller embedding dimension, 50 instead of 300\n",
    "- 2 filter sizes instead of original 3\n",
    "- fewer filters; original work uses 100, experiments show that 3-10 is enough;\n",
    "- random initialization is no worse than word2vec init on IMDB corpus\n",
    "- sliding Max Pooling instead of original Global Pooling\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import data_helpers\n",
    "from w2v import train_word2vec\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "import itertools\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set(style='whitegrid', palette='muted')\n",
    "\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Input, MaxPooling1D, Convolution1D, Embedding\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing import sequence\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    # list all data in history\n",
    "    print(history.history.keys())\n",
    "    # summarize history for accuracy\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "    # summarize history for loss\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "    \n",
    "def plot_confusion_matrix(model, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \n",
    "    y_pred = model.predict(x_test)\n",
    "    # print(y_pred[:10])\n",
    "    # print(y_test[:10])\n",
    "    class_labels = np.argmax(y_test, axis=1) \n",
    "    # print(class_labels[:10])\n",
    "    # print(y_pred.argmax(axis=1))\n",
    "    print(metrics.classification_report(class_labels, y_pred.argmax(axis=1), \n",
    "                                        target_names=data_train['label'].unique(), digits=3))\n",
    "    \n",
    "    cm = confusion_matrix(class_labels, \n",
    "                          y_pred.argmax(axis=1))\n",
    "    \n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "#     plt.figure(figsize=(12,8))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ---------------------- Parameters section -------------------\n",
    "#\n",
    "# Model type. See Kim Yoon's Convolutional Neural Networks for Sentence Classification, Section 3\n",
    "# model_type = \"CNN-non-static\"  # CNN-rand|CNN-non-static|CNN-static\n",
    "# model_type = 'CNN-rand'\n",
    "model_type = \"CNN-static\"  \n",
    "\n",
    "# Data source\n",
    "data_source = \"keras_data_set\"  # keras_data_set|local_dir\n",
    "\n",
    "# Model Hyperparameters\n",
    "embedding_dim = 50\n",
    "filter_sizes = (3, 8)\n",
    "num_filters = 10\n",
    "dropout_prob = (0.5, 0.8)\n",
    "hidden_dims = 50\n",
    "\n",
    "# Training parameters\n",
    "batch_size = 64\n",
    "num_epochs = 50\n",
    "\n",
    "# Prepossessing parameters\n",
    "sequence_length = 400\n",
    "max_words = 5000\n",
    "\n",
    "# Word2Vec parameters (see train_word2vec)\n",
    "min_word_count = 1\n",
    "context = 10\n",
    "\n",
    "#\n",
    "# ---------------------- Parameters end -----------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Conservative' 'Liberal' 'NDP']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0.1.1</th>\n",
       "      <th>index</th>\n",
       "      <th>FloorLanguage</th>\n",
       "      <th>SubjectOfBusinessTitle</th>\n",
       "      <th>content</th>\n",
       "      <th>date</th>\n",
       "      <th>number</th>\n",
       "      <th>orderOfBusinessCatchLine</th>\n",
       "      <th>...</th>\n",
       "      <th>personId</th>\n",
       "      <th>personSpeaking</th>\n",
       "      <th>session</th>\n",
       "      <th>speakerName</th>\n",
       "      <th>subjectOfBusinessId</th>\n",
       "      <th>volume</th>\n",
       "      <th>label</th>\n",
       "      <th>target</th>\n",
       "      <th>TokenizedContent</th>\n",
       "      <th>token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40402</th>\n",
       "      <td>39500</td>\n",
       "      <td>68145</td>\n",
       "      <td>68145</td>\n",
       "      <td>20</td>\n",
       "      <td>EN</td>\n",
       "      <td>Ethics</td>\n",
       "      <td>Mr. Speaker, in a typical day, how many times ...</td>\n",
       "      <td>2013-05-29</td>\n",
       "      <td>NUMBER 258</td>\n",
       "      <td>Oral Questions</td>\n",
       "      <td>...</td>\n",
       "      <td>181199</td>\n",
       "      <td>Hon. Thomas Mulcair (Leader of the Opposition,...</td>\n",
       "      <td>1st SESSION</td>\n",
       "      <td>Speaker: The Honourable Andrew Scheer</td>\n",
       "      <td>8041875</td>\n",
       "      <td>VOLUME 146</td>\n",
       "      <td>NDP</td>\n",
       "      <td>2</td>\n",
       "      <td>mr. speaker typic day mani time prime minist s...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40403</th>\n",
       "      <td>26454</td>\n",
       "      <td>44675</td>\n",
       "      <td>44675</td>\n",
       "      <td>56</td>\n",
       "      <td>EN</td>\n",
       "      <td>Consumer Protection</td>\n",
       "      <td>Mr. Speaker, it was this government that intro...</td>\n",
       "      <td>2015-06-19</td>\n",
       "      <td>NUMBER 235</td>\n",
       "      <td>Oral Questions</td>\n",
       "      <td>...</td>\n",
       "      <td>170855</td>\n",
       "      <td>Hon. Mike Lake (Parliamentary Secretary to the...</td>\n",
       "      <td>2nd SESSION</td>\n",
       "      <td>Speaker: The Honourable Andrew Scheer</td>\n",
       "      <td>8757840</td>\n",
       "      <td>VOLUME 147</td>\n",
       "      <td>Conservative</td>\n",
       "      <td>0</td>\n",
       "      <td>mr. speaker govern introduc legisl call fair p...</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40404</th>\n",
       "      <td>36118</td>\n",
       "      <td>62161</td>\n",
       "      <td>62161</td>\n",
       "      <td>64</td>\n",
       "      <td>EN</td>\n",
       "      <td>Search and Rescue</td>\n",
       "      <td>Mr. Speaker, last May, just days after the Con...</td>\n",
       "      <td>2012-12-04</td>\n",
       "      <td>NUMBER 191</td>\n",
       "      <td>Oral Questions</td>\n",
       "      <td>...</td>\n",
       "      <td>170758</td>\n",
       "      <td>Ms. Judy Foote (Random—Burin—St. George's, Lib.)</td>\n",
       "      <td>1st SESSION</td>\n",
       "      <td>Speaker: The Honourable Andrew Scheer</td>\n",
       "      <td>7835115</td>\n",
       "      <td>VOLUME 146</td>\n",
       "      <td>Liberal</td>\n",
       "      <td>1</td>\n",
       "      <td>mr. speaker last may day conserv close maritim...</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40405</th>\n",
       "      <td>36370</td>\n",
       "      <td>62610</td>\n",
       "      <td>62610</td>\n",
       "      <td>66</td>\n",
       "      <td>EN</td>\n",
       "      <td>Status of Women</td>\n",
       "      <td>Mr. Speaker, 25 years ago today, the Supreme C...</td>\n",
       "      <td>2013-01-28</td>\n",
       "      <td>NUMBER 198</td>\n",
       "      <td>Oral Questions</td>\n",
       "      <td>...</td>\n",
       "      <td>170756</td>\n",
       "      <td>Ms. Niki Ashton (Churchill, NDP)</td>\n",
       "      <td>1st SESSION</td>\n",
       "      <td>Speaker: The Honourable Andrew Scheer</td>\n",
       "      <td>7856038</td>\n",
       "      <td>VOLUME 146</td>\n",
       "      <td>NDP</td>\n",
       "      <td>2</td>\n",
       "      <td>mr. speaker   year ago today suprem court cana...</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40406</th>\n",
       "      <td>28183</td>\n",
       "      <td>47569</td>\n",
       "      <td>47569</td>\n",
       "      <td>22</td>\n",
       "      <td>EN</td>\n",
       "      <td>Canadian Wheat Board</td>\n",
       "      <td>Mr. Speaker, what we do respect is the right o...</td>\n",
       "      <td>2011-10-25</td>\n",
       "      <td>NUMBER 036</td>\n",
       "      <td>Oral Questions</td>\n",
       "      <td>...</td>\n",
       "      <td>111568</td>\n",
       "      <td>Hon. Gerry Ritz (Minister of Agriculture and A...</td>\n",
       "      <td>1st SESSION</td>\n",
       "      <td>Speaker: The Honourable Andrew Scheer</td>\n",
       "      <td>4441565</td>\n",
       "      <td>VOLUME 146</td>\n",
       "      <td>Conservative</td>\n",
       "      <td>0</td>\n",
       "      <td>mr. speaker respect right western canadian far...</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  Unnamed: 0.1  Unnamed: 0.1.1  index FloorLanguage  \\\n",
       "40402       39500         68145           68145     20            EN   \n",
       "40403       26454         44675           44675     56            EN   \n",
       "40404       36118         62161           62161     64            EN   \n",
       "40405       36370         62610           62610     66            EN   \n",
       "40406       28183         47569           47569     22            EN   \n",
       "\n",
       "      SubjectOfBusinessTitle  \\\n",
       "40402                 Ethics   \n",
       "40403    Consumer Protection   \n",
       "40404      Search and Rescue   \n",
       "40405        Status of Women   \n",
       "40406   Canadian Wheat Board   \n",
       "\n",
       "                                                 content        date  \\\n",
       "40402  Mr. Speaker, in a typical day, how many times ...  2013-05-29   \n",
       "40403  Mr. Speaker, it was this government that intro...  2015-06-19   \n",
       "40404  Mr. Speaker, last May, just days after the Con...  2012-12-04   \n",
       "40405  Mr. Speaker, 25 years ago today, the Supreme C...  2013-01-28   \n",
       "40406  Mr. Speaker, what we do respect is the right o...  2011-10-25   \n",
       "\n",
       "           number orderOfBusinessCatchLine     ...      personId  \\\n",
       "40402  NUMBER 258           Oral Questions     ...        181199   \n",
       "40403  NUMBER 235           Oral Questions     ...        170855   \n",
       "40404  NUMBER 191           Oral Questions     ...        170758   \n",
       "40405  NUMBER 198           Oral Questions     ...        170756   \n",
       "40406  NUMBER 036           Oral Questions     ...        111568   \n",
       "\n",
       "                                          personSpeaking      session  \\\n",
       "40402  Hon. Thomas Mulcair (Leader of the Opposition,...  1st SESSION   \n",
       "40403  Hon. Mike Lake (Parliamentary Secretary to the...  2nd SESSION   \n",
       "40404   Ms. Judy Foote (Random—Burin—St. George's, Lib.)  1st SESSION   \n",
       "40405                   Ms. Niki Ashton (Churchill, NDP)  1st SESSION   \n",
       "40406  Hon. Gerry Ritz (Minister of Agriculture and A...  1st SESSION   \n",
       "\n",
       "                                 speakerName subjectOfBusinessId      volume  \\\n",
       "40402  Speaker: The Honourable Andrew Scheer             8041875  VOLUME 146   \n",
       "40403  Speaker: The Honourable Andrew Scheer             8757840  VOLUME 147   \n",
       "40404  Speaker: The Honourable Andrew Scheer             7835115  VOLUME 146   \n",
       "40405  Speaker: The Honourable Andrew Scheer             7856038  VOLUME 146   \n",
       "40406  Speaker: The Honourable Andrew Scheer             4441565  VOLUME 146   \n",
       "\n",
       "              label  target  \\\n",
       "40402           NDP       2   \n",
       "40403  Conservative       0   \n",
       "40404       Liberal       1   \n",
       "40405           NDP       2   \n",
       "40406  Conservative       0   \n",
       "\n",
       "                                        TokenizedContent token_count  \n",
       "40402  mr. speaker typic day mani time prime minist s...          11  \n",
       "40403  mr. speaker govern introduc legisl call fair p...          50  \n",
       "40404  mr. speaker last may day conserv close maritim...          56  \n",
       "40405  mr. speaker   year ago today suprem court cana...          44  \n",
       "40406  mr. speaker respect right western canadian far...          54  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAEwCAYAAABVOh3JAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3X9UVPed//HnZAyJ9QcgyTDIIlkMPckq/jjE07IoZscC\nyo8wRklPds1G1qxbtXrU3faE2iWGGJNsc7KhYZuE2mNsk/assQqR0UgZG5G2Wes0HkKqe9Y0s4sS\nZhJQFKPBwHz/4GR2+QLy03sHeD3OyQm85w6f9z13nNfcz713riUQCAQQEZFx7RazGxAREfMpDERE\nRGEgIiIKAxERQWEgIiIoDEREBJhgdgND5fF4zG5BRGRUSk5O7lEbtWEAva/QWOHxeMb0+o1l2naj\n21jffn19kO53mujjjz/mkUceYdmyZWRnZ7Nnzx4ALl68SEFBARkZGRQUFNDa2gpAIBBgx44dpKen\nk5ubywcffBD8WwcOHCAjI4OMjAwOHDgQrNfX15Obm0t6ejo7duxA18GJiBir3zCwWq08/vjjHD58\nmH//93/n5z//OWfPnqWsrIyUlBSqqqpISUmhrKwMgJqaGrxeL1VVVTz11FNs374d6AqP0tJS9u7d\ny5tvvklpaWkwQLZv305xcTFVVVV4vV5qampu3hqLiEgP/YaBzWZj1qxZAEyePJmEhAR8Ph9utxun\n0wmA0+mkuroaIFi3WCzMmzePS5cu4ff7qa2tJTU1lYiICMLDw0lNTeX48eP4/X7a2tqYP38+FosF\np9OJ2+2+iassIiL/v0EdMzh37hynT59m7ty5NDc3Y7PZgK7AaGlpAcDn82G324PPsdvt+Hy+HvXo\n6Ohe618uPxBj/SDyWF+/sUzbbnQbj9tvwGFw5coVNm3axPe+9z0mT57c53K9zfdbLJZB1wdirB/k\nGcvrN5Zp241uY337DfkAMsD169fZtGkTubm5ZGRkABAVFYXf7wfA7/czbdo0oOuTfVNTU/C5TU1N\n2Gy2HnWfz9dr/cvlRUTEOP2GQSAQYNu2bSQkJFBQUBCsOxwOysvLASgvL2fJkiXd6oFAgFOnTjFl\nyhRsNhsLFy6ktraW1tZWWltbqa2tZeHChdhsNiZNmsSpU6cIBALd/paIiBij32kij8dDRUUFX/3q\nV8nLywNg69atrF27ls2bN7Nv3z5iYmIoKSkBYPHixRw7doz09HQmTpzIzp07AYiIiGD9+vWsXLkS\ngA0bNhAREQF0nU1UWFjItWvXSEtLIy0t7aasrIiI9M4yWm9uY/S83uvVHxs2FkBj48dMnx5j2Hir\nvmHcWGPdWJ9zHuvG+vbra/303UQiIqIwEBERhYGIiKAwEBERFAYiIoLCQEREUBiIiAgKAxERQWEg\nIiIoDEREBIWBiIigMBARERQGIiKCwkBERFAYiIgICgMREUFhICIiDOC2l4WFhbzzzjtERUVRWVkJ\nwObNm/noo48AuHz5MlOmTKGiooJz586RlZXFn//5nwMwd+5ciouLAaivrw/e2nLx4sVs27YNi8XC\nxYsX2bJlC+fPnyc2NpYXX3yR8PDwm7W+IiLSi373DB588EF27drVrfbiiy9SUVFBRUUFGRkZpKen\nBx+bMWNG8LEvgwC67nNcXFxMVVUVXq+XmpoaAMrKykhJSaGqqoqUlBTKyspGat1ERGSA+g2DBQsW\n9PlJPRAIcPjwYXJycm74N/x+P21tbcyfPx+LxYLT6cTtdgPgdrtxOp0AOJ1OqqurB7sOIiIyTMM6\nZnDy5EmioqK46667grVz587hdDpZtWoVJ0+eBMDn82G324PL2O12fD4fAM3NzdhsNgBsNhstLS3D\naUlERIag32MGN1JZWdltr8Bms/HrX/+ayMhI6uvr2bBhAy6Xi0Ag0OO5FotlOEMD4PF4hv03Bqqx\ncfj9Dn7Mjw0by+NpNGys8cDI16aMvPG4/YYcBl988QW/+tWv2L9/f7AWFhZGWFgYALNnz2bGjBl8\n9NFH2O12mpqagss1NTUF9waioqLw+/3YbDb8fj/Tpk0bcA/JyclDbX/QTl8w7o0ZuoJg+vQYw8ZL\nTjZurLHO4/EY+tqUkTXWt19fQTfkaaLf/va3JCQkdJv+aWlpoaOjA4CGhga8Xi9xcXHYbDYmTZrE\nqVOnCAQClJeXs2TJEgAcDgfl5eUA3eoiImKcfvcMtm7dyokTJ7hw4QJpaWls3LiR/Px8Dh06RHZ2\ndrdlf//73/PDH/4Qq9WK1WrlySefJCIiAug6m+jLU0vT0tJIS0sDYO3atWzevJl9+/YRExNDSUnJ\nTVhNERG5EUugtwn9UcDoXbnXq8f2NNGqb2iaaKSM9WmGsW6sb7++1k9XIIuIiMJAREQUBiIigsJA\nRERQGIiICAoDERFBYSAiIigMREQEhYGIiKAwEBERFAYiIoLCQEREUBiIiAgKAxERQWEgIiIoDERE\nBIWBiIigMBAREQYQBoWFhaSkpJCTkxOsvfTSSyxatIi8vDzy8vI4duxY8LFXX32V9PR0MjMzOX78\neLBeU1NDZmYm6enplJWVBesNDQ3k5+eTkZHB5s2baW9vH6l1ExGRAeo3DB588EF27drVo7569Woq\nKiqoqKhg8eLFAJw9exaXy4XL5WLXrl08+eSTdHR00NHRQXFxMbt27cLlclFZWcnZs2cBeP7551m9\nejVVVVVMnTqVffv2jfAqiohIf/oNgwULFhAeHj6gP+Z2u8nOziYsLIy4uDji4+Opq6ujrq6O+Ph4\n4uLiCAsLIzs7G7fbTSAQ4N133yUzMxOA5cuX43a7h7dGIiIyaBOG+sQ33niD8vJyZs+ezeOPP054\neDg+n4+5c+cGl4mOjsbn8wFgt9u71evq6rhw4QJTp05lwoQJwWW+XH4gPB7PUNsftMZGi2Fj/e+Y\nHxs2lsfTaNhY44GRr00ZeeNx+w0pDB5++GHWr1+PxWKhpKSEZ599lmeeeYZAINBjWYvFQmdnZ6/1\n3vRV701ycvLAmx6m0xeMe2OGriCYPj3GsPGSk40ba6zzeDyGvjZlZI317ddX0A3pbKI77rgDq9XK\nLbfcQn5+Pu+//z7Q9cm+qakpuJzP58Nms/VZj4yM5NKlS3zxxRcANDU1YbPZhtKSiIgMw5DCwO/3\nB3+urq4mMTERAIfDgcvlor29nYaGBrxeL3PmzCEpKQmv10tDQwPt7e24XC4cDgcWi4Wvfe1rHDly\nBIADBw7gcDhGYLVERGQw+p0m2rp1KydOnODChQukpaWxceNGTpw4wZkzZwCIjY2luLgYgMTERJYt\nW0ZWVhZWq5WioiKsVisARUVFPPbYY3R0dLBixYpggHznO99hy5YtvPjii9x7773k5+ffrHUVEZE+\nWAK9TfSPAkbP671ePbaPGaz6ho4ZjJSxPuc81o317dfX+ukKZBERURiIiIjCQEREUBiIiAgKAxER\nQWEgIiIoDEREBIWBiIigMBARERQGIiKCwkBERFAYiIgICgMREUFhICIiKAxERASFgYiIoDAQEREG\nEAaFhYWkpKSQk5MTrD333HMsXbqU3NxcNmzYwKVLlwA4d+4cc+bMIS8vj7y8PIqKioLPqa+vJzc3\nl/T0dHbs2MGXN1i7ePEiBQUFZGRkUFBQQGtr60ivo4iI9KPfMHjwwQfZtWtXt1pqaiqVlZUcPHiQ\nu+66i1dffTX42IwZM6ioqKCioiJ4b2SA7du3U1xcTFVVFV6vl5qaGgDKyspISUmhqqqKlJQUysrK\nRmrdRERkgPoNgwULFhAeHt6ttnDhQiZMmADAvHnzaGpquuHf8Pv9tLW1MX/+fCwWC06nE7fbDYDb\n7cbpdALgdDqprq4e0oqIiMjQDfuYwS9/+UvS0tKCv587dw6n08mqVas4efIkAD6fD7vdHlzGbrfj\n8/kAaG5uxmazAWCz2WhpaRluSyIiMkgThvPkl19+GavVygMPPAB0vZn/+te/JjIykvr6ejZs2IDL\n5QoeH/i/LBbLcIYGwOPxDPtvDFRj4/D7HfyYHxs2lsfTaNhY44GRr00ZeeNx+w05DA4cOMA777zD\na6+9FnxjDwsLIywsDIDZs2czY8YMPvroI+x2e7eppKampuDeQFRUFH6/H5vNht/vZ9q0aQPuITk5\neajtD9rpC8a9MUNXEEyfHmPYeMnJxo011nk8HkNfmzKyxvr26yvohjRNVFNTw49//GNefvllJk6c\nGKy3tLTQ0dEBQENDA16vl7i4OGw2G5MmTeLUqVMEAgHKy8tZsmQJAA6Hg/LycoBudRERMU6/ewZb\nt27lxIkTXLhwgbS0NDZu3EhZWRnt7e0UFBQAMHfuXIqLi/n973/PD3/4Q6xWK1arlSeffJKIiAig\n62yiwsJCrl27RlpaWvA4w9q1a9m8eTP79u0jJiaGkpKSm7i6IiLSm37D4IUXXuhRy8/P73XZzMxM\nMjMze30sKSmJysrKHvXIyEj27NnTXxsiInIT6QpkERFRGIiIiMJAREQY5nUGIqPB69VGnxZsMfRU\n5FXf0GnBMnzaMxAREYWBiIgoDEREBIWBiIigMBARERQGIiKCwkBERFAYiIgICgMREUFhICIiKAxE\nRASFgYiIoDAQEREUBiIiwgDDoLCwkJSUFHJycoK1ixcvUlBQQEZGBgUFBbS2tgIQCATYsWMH6enp\n5Obm8sEHHwSfc+DAATIyMsjIyODAgQPBen19Pbm5uaSnp7Njxw4CgcBIrZ+IiAzAgMLgwQcfZNeu\nXd1qZWVlpKSkUFVVRUpKCmVlZQDU1NTg9XqpqqriqaeeYvv27UBXeJSWlrJ3717efPNNSktLgwGy\nfft2iouLqaqqwuv1UlNTM4KrKCIi/RlQGCxYsIDw8PBuNbfbjdPpBMDpdFJdXd2tbrFYmDdvHpcu\nXcLv91NbW0tqaioRERGEh4eTmprK8ePH8fv9tLW1MX/+fCwWC06nE7fbPcKrKSIiNzLkO501Nzdj\ns9kAsNlstLS0AODz+bDb7cHl7HY7Pp+vRz06OrrX+pfLD4TH4xlq+4PW2GgxbKz/HdO4u2V5PI2G\njWU0bTsZLCPfW0LFiN/2srf5fovFMuj6QCQnJw++wSEy8jaG0PVmMn26cbczTE4eu7dO1LaTwfB4\nPIa+txitr6Ab8tlEUVFR+P1+APx+P9OmTQO6Ptk3NTUFl2tqasJms/Wo+3y+XutfLi8iIsYZchg4\nHA7Ky8sBKC8vZ8mSJd3qgUCAU6dOMWXKFGw2GwsXLqS2tpbW1lZaW1upra1l4cKF2Gw2Jk2axKlT\npwgEAt3+loiIGGNA00Rbt27lxIkTXLhwgbS0NDZu3MjatWvZvHkz+/btIyYmhpKSEgAWL17MsWPH\nSE9PZ+LEiezcuROAiIgI1q9fz8qVKwHYsGEDERERQNfZRIWFhVy7do20tDTS0tJuxrqKiEgfBhQG\nL7zwQq/1PXv29KhZLBaeeOKJXpdfuXJlMAz+r6SkJCorKwfSioiI3AS6AllERBQGIiKiMBAREW7C\ndQYiIiPp9WqjrxOxGHptyqpvhMZ1ItozEBERhYGIiCgMREQEhYGIiKAwEBERFAYiIoLCQEREUBiI\niAgKAxERQWEgIiIoDEREBIWBiIigMBAREYbxraV/+tOf2LJlS/D3hoYGNm3axOXLl9m7dy/Tpk0D\num6ZuXjxYgBeffVV9u3bxy233ML3v/99Fi1aBEBNTQ1PP/00nZ2d5Ofns3bt2uGsk4iIDNKQwyAh\nIYGKigoAOjo6SEtLIz09nf3797N69WrWrFnTbfmzZ8/icrlwuVz4fD4KCgo4cuQIAMXFxezevZvo\n6GhWrlyJw+Hg7rvvHsZqiYjIYIzI/Qx+97vfERcXR2xsbJ/LuN1usrOzCQsLIy4ujvj4eOrq6gCI\nj48nLi4OgOzsbNxut8JARMRAI3LMwOVykZOTE/z9jTfeIDc3l8LCQlpbWwHw+XzY7fbgMtHR0fh8\nvj7rIiJinGHvGbS3t3P06FH+8R//EYCHH36Y9evXY7FYKCkp4dlnn+WZZ54hEAj0eK7FYqGzs7PX\n+kB4PJ7hNT8IjY0D62lkxzTubkseT6NhYxlN22500/YzxrDDoKamhlmzZnHHHXcABP8PkJ+fz7e+\n9S0A7HY7TU1Nwcd8Ph82mw2gz3p/kpOTh9v+gBl5GzzoejFOn27c7fCSk0Pj1ns3g7bd6KbtN7L6\n+hA97Gkil8tFdnZ28He/3x/8ubq6msTERAAcDgcul4v29nYaGhrwer3MmTOHpKQkvF4vDQ0NtLe3\n43K5cDgcw21LREQGYVh7BlevXuW3v/0txcXFwdoPfvADzpw5A0BsbGzwscTERJYtW0ZWVhZWq5Wi\noiKsVisARUVFPPbYY3R0dLBixYpggIiIiDGGFQYTJ07kP/7jP7rVfvCDH/S5/Lp161i3bl2P+uLF\ni4PXIoiIiPF0BbKIiCgMREREYSAiIigMREQEhYGIiKAwEBERFAYiIoLCQEREUBiIiAgKAxERQWEg\nIiIoDEREBIWBiIigMBARERQGIiKCwkBERFAYiIgICgMREWGYt72ErhvdT5o0iVtuuQWr1cr+/fu5\nePEiW7Zs4fz588TGxvLiiy8SHh5OIBDg6aef5tixY9x+++08++yzzJo1C4ADBw7w8ssvA123x1y+\nfPlwWxMRkQEakT2DPXv2UFFRwf79+wEoKysjJSWFqqoqUlJSKCsrA6Cmpgav10tVVRVPPfUU27dv\nB+DixYuUlpayd+9e3nzzTUpLS2ltbR2J1kREZABuyjSR2+3G6XQC4HQ6qa6u7la3WCzMmzePS5cu\n4ff7qa2tJTU1lYiICMLDw0lNTeX48eM3ozUREenFsKeJANasWYPFYuGb3/wm3/zmN2lubsZmswFg\ns9loaWkBwOfzYbfbg8+z2+34fL4e9ejoaHw+X7/jejyekWh/QBobLYaN9b9jfmzYWB5Po2FjGU3b\nbnTT9jPGsMPgF7/4BdHR0TQ3N1NQUEBCQkKfywYCgR41i8XSZ70/ycnJg2t2GE5fMO7FAV0vxunT\nYwwbLznZuLGMpm03umn7jay+PkQPe5ooOjoagKioKNLT06mrqyMqKgq/3w+A3+9n2rRpQNeeQFNT\nU/C5TU1N2Gy2HnWfzxfcsxARkZtvWGHw2Wef0dbWFvz5N7/5DYmJiTgcDsrLywEoLy9nyZIlAMF6\nIBDg1KlTTJkyBZvNxsKFC6mtraW1tZXW1lZqa2tZuHDhMFdNREQGaljTRM3NzWzYsAGAjo4OcnJy\nSEtLIykpic2bN7Nv3z5iYmIoKSkBYPHixRw7doz09HQmTpzIzp07AYiIiGD9+vWsXLkSgA0bNhAR\nETGc1kREZBCGFQZxcXG89dZbPeqRkZHs2bOnR91isfDEE0/0+rdWrlwZDAMRETGWrkAWERGFgYiI\nKAxERASFgYiIoDAQEREUBiIigsJARERQGIiICAoDERFBYSAiIigMREQEhYGIiKAwEBERFAYiIoLC\nQEREUBiIiAgKAxERYRhh8PHHH/PII4+wbNkysrOzg3c2e+mll1i0aBF5eXnk5eVx7Nix4HNeffVV\n0tPTyczM5Pjx48F6TU0NmZmZpKenU1ZWNozVERGRoRjybS+tViuPP/44s2bNoq2tjRUrVpCamgrA\n6tWrWbNmTbflz549i8vlwuVy4fP5KCgo4MiRIwAUFxeze/duoqOjWblyJQ6Hg7vvvnsYqyUiIoMx\n5DCw2WzYbDYAJk+eTEJCAj6fr8/l3W432dnZhIWFERcXR3x8PHV1dQDEx8cTFxcHQHZ2Nm63W2Eg\nImKgETlmcO7cOU6fPs3cuXMBeOONN8jNzaWwsJDW1lYAfD4fdrs9+Jzo6Gh8Pl+fdRERMc6Q9wy+\ndOXKFTZt2sT3vvc9Jk+ezMMPP8z69euxWCyUlJTw7LPP8swzzxAIBHo812Kx0NnZ2Wt9IDwez3Db\nH7DGxoH1NLJjfmzYWB5Po2FjGU3bbnTT9jPGsMLg+vXrbNq0idzcXDIyMgC44447go/n5+fzrW99\nCwC73U5TU1PwMZ/PF5xm6qven+Tk5OG0PyinLxj34oCuF+P06TGGjZecbNxYRtO2G920/UZWXx+i\nhzxNFAgE2LZtGwkJCRQUFATrfr8/+HN1dTWJiYkAOBwOXC4X7e3tNDQ04PV6mTNnDklJSXi9Xhoa\nGmhvb8flcuFwOIbaloiIDMGQ9ww8Hg8VFRV89atfJS8vD4CtW7dSWVnJmTNnAIiNjaW4uBiAxMRE\nli1bRlZWFlarlaKiIqxWKwBFRUU89thjdHR0sGLFimCAiIiIMYYcBvfddx//+Z//2aO+ePHiPp+z\nbt061q1b1+tzbvQ8ERG5uXQFsoiIKAxERERhICIiKAxERASFgYiIoDAQEREUBiIigsJARERQGIiI\nCAoDERFBYSAiIigMREQEhYGIiKAwEBERFAYiIoLCQEREUBiIiAgKAxERIYTCoKamhszMTNLT0ykr\nKzO7HRGRcSUkwqCjo4Pi4mJ27dqFy+WisrKSs2fPmt2WiMi4ERJhUFdXR3x8PHFxcYSFhZGdnY3b\n7Ta7LRGRcWOC2Q0A+Hw+7HZ78Pfo6Gjq6ur6fZ7H47mZbXVzb6RhQ/2f8RoNG8/jMW4so2nbjW7a\nfsYIiTAIBAI9ahaL5YbPSU5OvlntiIiMOyExTWS322lqagr+7vP5sNlsJnYkIjK+hEQYJCUl4fV6\naWhooL29HZfLhcPhMLstEZFxIySmiSZMmEBRURGPPfYYHR0drFixgsTERLPbEhEZNyyB3ibsRURk\nXAmJaSIRETGXwkBERBQGIiKiMBARERQGIeOjjz7i0UcfJScnB4AzZ87wox/9yOSuRMY2r9fLunXr\nyMnJYevWrfh8PrNbMo3OJgoRq1at4rvf/S5FRUWUl5cDkJOTQ2VlpcmdyY3Mnz+/16vlA4EAFouF\nP/zhDyZ0JQP113/91zidTu677z6OHj3KqVOnKC0tNbstU4TEdQYCV69eZc6cOd1qVqvVpG5koN57\n7z2zW5BhuHLlCg899BAACQkJLF++3OSOzKMwCBGRkZH8z//8T/BT5ttvv82dd95pclcyWM3NzXz+\n+efB36dPn25iN9Kfzz//nD/+8Y/B70e7du1at99nzZplZnuG0jRRiGhoaOCf//mfee+995g6dSp/\n9md/xvPPP09sbKzZrckAuN1unnvuOfx+P9OmTaOxsZGZM2ficrnMbk1u4JFHHunzMYvFwk9/+lMD\nuzGXwiBEdHR0YLVa+eyzz+js7GTy5MlmtySD8MADD7Bnzx4KCgooLy/n3XffxeVy8dRTT5ndmsiA\naJooRCxZsoRFixaRlZXF17/+dbPbkUGaMGECkZGRdHZ20tnZyde//nWef/55s9uSAbhw4QKVlZX8\n6U9/AmDmzJnk5OQQERFhcmfG0qmlIeLtt98mJSWFN954gyVLllBcXMzJkyfNbksGaOrUqVy5coUF\nCxbwT//0T+zYsYMJE/RZK9R9+OGH5Obm8sEHH3DXXXcRHx/P+++/T05ODh9++KHZ7RlK00QhqLW1\nlaeffpqDBw9y+vRps9uRAfjss8+4/fbb6ezs5ODBg1y+fJnc3FwiIw2+TZcMyqZNm1i6dClZWVnd\n6keOHKGyspKXXnrJpM6MpzAIISdOnODQoUPU1NSQlJREVlYWmZmZZrcl/ejo6GDNmjW89tprZrci\ng5SZmcmRI0cG/dhYpP3YEOFwOLj33ntZtmwZ3/3ud/nKV75idksyQFarldtvv53Lly8zZcoUs9uR\nQbjRv7Px9m9QYRAi3nrrLZ1BNIrddttt5Obm8pd/+Zfd3kS+//3vm9iV9Ke5uZndu3f3qAcCAVpa\nWkzoyDwKA5P9+Mc/5u///u/513/9116/1kBvJqPD/fffz/333292GzJIDz30EFeuXOn1sfz8fIO7\nMZfCwGQzZ84EYPbs2SZ3IsOxfPlyrl27RmNjIwkJCWa3IwP07W9/2+wWQobCwGQOhwOA22+/nWXL\nlnV77PDhw2a0JENw9OhRnnvuOa5fv87Ro0c5ffo0JSUlvPLKK2a3Jjdwoy+ls1gsbNiwwcBuzKXr\nDEJEWVnZgGoSmkpLS9m3bx9Tp04F4N577+X8+fMmdyX9+cpXvtLjP4Bf/vKX7Nq1y+TujKU9A5Md\nO3aMmpoafD4fO3bsCNbb2tr0raWjiNVq1ZlEo9Df/d3fBX9ua2vjpz/9Kfv37ycrK6vbY+OBwsBk\n0dHRzJ49m6NHj3b7hsRJkyZRWFhoYmcyGImJiRw8eJCOjg68Xi8/+9nPmD9/vtltyQBcvHiR3bt3\nc/DgQZYvX86BAwcIDw83uy3D6aKzEHH9+nVuvfVWs9uQIbp69SqvvPIKtbW1BAIBFi1axPr167nt\nttvMbk1u4LnnnuNXv/oVDz30EH/zN3/DpEmTzG7JNAqDEOH1ennhhRc4e/Zst+/Dd7vdJnYlg9XW\n1gaga0ZGiXvuuYewsDCsVmu3U7vH453qNE0UIgoLC9m0aRM7d+4Mzlsqp0ePuro6tm3bFjxnffLk\nyezcuVOnDIe4M2fOmN1CyNDZRCHi888/JyUlBYDY2Fg2btzIu+++a3JXMlDbtm3jiSee4OjRoxw9\nepSioiId85FRRXsGISIsLIzOzk7i4+N5/fXXiY6Oprm52ey2ZIAmTZrEfffdF/z9vvvuG9fzzzL6\n6JhBiKirq2PmzJlcvnyZkpIS2traWLNmDfPmzTO7NbmBDz74AICKigquXbtGdnY2FouFQ4cOER4e\nzpYtW0zuUGRgFAYh4o9//CN/8Rd/YXYbMki6h66MFQqDEPHII4/wySefsHTpUrKzs0lMTDS7JREZ\nRxQGIeSTTz7h8OHDHDp0iCtXrrBs2TLWr19vdltyAxUVFeTl5fX6NcgABQUFBnckMjQ6myiE3Hnn\nnfzt3/4tTz75JPfccw8/+tGPzG5J+nH16lUArly50ut/IqOF9gxCxIcffsihQ4c4cuQIERERwVte\nRkVFmd2aDNFrr73G6tWrzW5DZEAUBiHioYceIjs7m6VLlxIdHW12OzIC7r//ft555x2z2xAZEF1n\nEAI6Ojouui0dAAADfUlEQVSIi4vj0UcfNbsVGUH6nCWjiY4ZhACr1crFixdpb283uxUZQb3dxlQk\nVGnPIETExsby8MMP43A4ut1QXWejhLb58+f3+qYfCAS6feGgSKhTGIQIm82GzWYjEAjoLJRR5L33\n3jO7BZERoQPIIeazzz7rtmcgImIEHTMIEe+99x5ZWVlkZWUBXV+tu337dnObEpFxQ2EQInbu3MlP\nfvITIiIigK6bbpw8edLkrkRkvFAYhJCYmJhuv99yizaPiBhDB5BDRExMDH/4wx+wWCy0t7fzs5/9\njJkzZ5rdloiMEzqAHCJaWlp4+umn+d3vfkcgECA1NZVt27YRGRlpdmsiMg4oDERERMcMQsW//Mu/\n0NbWxvXr13n00Uf52te+RkVFhdlticg4oTAIEb/5zW+YPHky77zzDna7nSNHjvCTn/zE7LZEZJxQ\nGISIL774AoBjx46RnZ0dPMVURMQICoMQ8Vd/9VcsXbqU+vp6UlJSaGlp4bbbbjO7LREZJ3QAOYS0\ntrYyefJkrFYrV69epa2tjTvvvNPstkRkHNB1BiHkww8/5Pz583R0dARrTqfTxI5EZLxQGISI73zn\nOzQ0NHDPPfdgtVqBru/DVxiIiBEUBiGivr6eQ4cO6YYoImIKHUAOEYmJiXzyySdmtyEi45T2DELE\nhQsXyM7OZs6cOdx6663B+iuvvGJiVyIyXigMQsTGjRvNbkFExjGdWhpCPv30U95//30A5syZQ1RU\nlMkdich4oWMGIeLQoUPk5+fz9ttvc/jw4eDPIiJG0J5BiHjggQfYvXt3cG+gpaWF1atX89Zbb5nc\nmYiMB9ozCBGBQKDbtFBERATKaRExig4gh4iFCxeyZs0asrOzga5po7S0NJO7EpHxQtNEJvvv//5v\nPv30U5KTk6mqqsLj8RAIBJg6dSoPPPAAM2bMMLtFERkHFAYm+4d/+Ae2bNnCPffc063+/vvv82//\n9m+6zkBEDKFjBiY7f/58jyAASEpK4vz58yZ0JCLjkcLAZJ9//nmfj127ds3ATkRkPFMYmCwpKYm9\ne/f2qL/55pvMmjXLhI5EZDzSMQOTffrpp3z729/m1ltvDb7519fXc/36dUpLS3VzGxExhMIgRLz7\n7rv813/9FwB33303KSkpJnckIuOJwkBERHTMQEREFAYiIoLCQEREUBiIiAgKAxERAf4foVcuVQQI\nMd0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7eb2e70908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_train = pd.read_csv('../data/hansard_processed_all.csv')\n",
    "from sklearn.utils import shuffle\n",
    "data_train = shuffle(data_train).reset_index(drop=True)\n",
    "\n",
    "# filter for experiment\n",
    "# data_train = data_train[:50000]\n",
    "\n",
    "labels = data_train['label'].unique()\n",
    "print(labels)\n",
    "data_train['label'].value_counts().plot(kind='bar', alpha=.5)\n",
    "data_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "3 classes\n",
      "x_train shape: (32325, 200)\n",
      "x_test shape: (8082, 200)\n",
      "y_train shape: (32325, 3)\n",
      "y_test shape: (8082, 3)\n",
      "Found 18856 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "max_words = 20000\n",
    "MAX_SEQUENCE_LENGTH = 200\n",
    "EMBEDDING_DIM = 300\n",
    "\n",
    "def load_data_hansard(data_train):\n",
    "    print('Loading data...')\n",
    "\n",
    "    tokenizer = Tokenizer(num_words=max_words,lower=True, split=' ', \n",
    "                          filters='\"#%&()*+-/<=>@[\\\\]^_`{|}~\\t\\n',\n",
    "                          char_level=False, oov_token=u'<UNK>')\n",
    "\n",
    "    tokenizer.fit_on_texts(data_train['TokenizedContent'].values)\n",
    "\n",
    "    X = tokenizer.texts_to_sequences(data_train['TokenizedContent'].values)\n",
    "    Y = pd.get_dummies(data_train['label']).values\n",
    "    # print(X[0])\n",
    "\n",
    "    X = pad_sequences(X, maxlen=MAX_SEQUENCE_LENGTH,  padding=\"post\", truncating=\"post\")\n",
    "    # print(X[10])\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, \n",
    "                                                        random_state = 42)\n",
    "\n",
    "    # print(y_train[100])\n",
    "\n",
    "    num_classes = y_train.shape[1]\n",
    "    print(num_classes, 'classes')\n",
    "\n",
    "    print('x_train shape:', x_train.shape)\n",
    "    print('x_test shape:', x_test.shape)\n",
    "\n",
    "    print('y_train shape:', y_train.shape)\n",
    "    print('y_test shape:', y_test.shape)\n",
    "    \n",
    "    vocabulary_inv = tokenizer.word_index\n",
    "    vocabulary_inv = dict((v, k) for k, v in vocabulary_inv.items())\n",
    "    print('Found %s unique tokens.' % len(vocabulary_inv))\n",
    "    \n",
    "#     print(tokenizer.word_index)\n",
    "#     print('vocabulary: ', vocabulary_inv)\n",
    "    \n",
    "#     vocabulary, vocabulary_inv = data_helpers.build_vocab(data_train['TokenizedContent'].values)    \n",
    "    return x_train, y_train, x_test, y_test, vocabulary_inv\n",
    "\n",
    "x_train, y_train, x_test, y_test, vocabulary_inv = load_data_hansard(data_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_data(data_source):\n",
    "    assert data_source in [\"keras_data_set\", \"local_dir\"], \"Unknown data source\"\n",
    "    if data_source == \"keras_data_set\":\n",
    "        (x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_words, start_char=None,\n",
    "                                                              oov_char=None, index_from=None)\n",
    "\n",
    "        x_train = sequence.pad_sequences(x_train, maxlen=sequence_length, padding=\"post\", truncating=\"post\")\n",
    "        x_test = sequence.pad_sequences(x_test, maxlen=sequence_length, padding=\"post\", truncating=\"post\")\n",
    "\n",
    "        vocabulary = imdb.get_word_index()\n",
    "        vocabulary_inv = dict((v, k) for k, v in vocabulary.items())\n",
    "        vocabulary_inv[0] = \"<PAD/>\"\n",
    "    else:\n",
    "        x, y, vocabulary, vocabulary_inv_list = data_helpers.load_data()\n",
    "        vocabulary_inv = {key: value for key, value in enumerate(vocabulary_inv_list)}\n",
    "        y = y.argmax(axis=1)\n",
    "\n",
    "        # Shuffle data\n",
    "        shuffle_indices = np.random.permutation(np.arange(len(y)))\n",
    "        x = x[shuffle_indices]\n",
    "        y = y[shuffle_indices]\n",
    "        train_len = int(len(x) * 0.9)\n",
    "        x_train = x[:train_len]\n",
    "        y_train = y[:train_len]\n",
    "        x_test = x[train_len:]\n",
    "        y_test = y[train_len:]\n",
    "        \n",
    "#     print(vocabulary_inv)\n",
    "\n",
    "    return x_train, y_train, x_test, y_test, vocabulary_inv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data...\n",
      "Loading data...\n",
      "3 classes\n",
      "x_train shape: (32325, 200)\n",
      "x_test shape: (8082, 200)\n",
      "y_train shape: (32325, 3)\n",
      "y_test shape: (8082, 3)\n",
      "Found 18856 unique tokens.\n",
      "Adjusting sequence length for actual size\n",
      "x_train shape: (32325, 200)\n",
      "x_test shape: (8082, 200)\n",
      "Vocabulary Size: 18856\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Data Preparation\n",
    "print(\"Load data...\")\n",
    "# x_train, y_train, x_test, y_test, vocabulary_inv = load_data(data_source)\n",
    "x_train, y_train, x_test, y_test, vocabulary_inv = load_data_hansard(data_train)\n",
    "\n",
    "if sequence_length != x_test.shape[1]:\n",
    "    print(\"Adjusting sequence length for actual size\")\n",
    "    sequence_length = x_test.shape[1]\n",
    "\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(\"x_test shape:\", x_test.shape)\n",
    "print(\"Vocabulary Size: {:d}\".format(len(vocabulary_inv)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model type is CNN-static\n",
      "Load existing Word2Vec model '50features_1minwords_10context'\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'slice'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-b0500c1033c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmodel_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"CNN-static\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_weights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0membedding_weights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mx_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0membedding_weights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'slice'"
     ]
    }
   ],
   "source": [
    "# Prepare embedding layer weights and convert inputs for static model\n",
    "print(\"Model type is\", model_type)\n",
    "if model_type in [\"CNN-non-static\", \"CNN-static\"]:\n",
    "    embedding_weights = train_word2vec(np.vstack((x_train, x_test)), vocabulary_inv, \n",
    "                                       sentences=data_train['TokenizedContent'].values,\n",
    "                                       model_name='/home/paperspace/.keras/datasets/GoogleNews-vectors-negative300.bin'\n",
    "                                       num_features=embedding_dim,\n",
    "                                       min_word_count=min_word_count, context=context)\n",
    "    \n",
    "    if model_type == \"CNN-static\":\n",
    "        \n",
    "        x_train = np.stack([np.stack([embedding_weights[word] for word in sentence]) for sentence in x_train])\n",
    "        x_test = np.stack([np.stack([embedding_weights[word] for word in sentence]) for sentence in x_test])\n",
    "        print(\"x_train static shape:\", x_train.shape)\n",
    "        print(\"x_test static shape:\", x_test.shape)\n",
    "\n",
    "elif model_type == \"CNN-rand\":\n",
    "    embedding_weights = None\n",
    "else:\n",
    "    raise ValueError(\"Unknown model type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model type is CNN-static\n",
      "Load existing Word2Vec model '50features_1minwords_10context'\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-18d6386df6ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m                                        min_word_count=min_word_count, context=context)\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmodel_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"CNN-static\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0membedding_weights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mx_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0membedding_weights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"x_train static shape:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-18d6386df6ea>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      8\u001b[0m                                        min_word_count=min_word_count, context=context)\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmodel_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"CNN-static\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0membedding_weights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mx_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0membedding_weights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"x_train static shape:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-18d6386df6ea>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      8\u001b[0m                                        min_word_count=min_word_count, context=context)\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmodel_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"CNN-static\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0membedding_weights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mx_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0membedding_weights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"x_train static shape:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Build model\n",
    "if model_type == \"CNN-static\":\n",
    "    input_shape = (sequence_length, embedding_dim)\n",
    "else:\n",
    "    input_shape = (sequence_length,)\n",
    "\n",
    "model_input = Input(shape=input_shape)\n",
    "\n",
    "# Static model does not have embedding layer\n",
    "if model_type == \"CNN-static\":\n",
    "    z = model_input\n",
    "else:\n",
    "    z = Embedding(len(vocabulary_inv), \n",
    "                  embedding_dim, input_length=sequence_length, \n",
    "                  name=\"embedding\")(model_input)\n",
    "\n",
    "z = Dropout(dropout_prob[0])(z)\n",
    "\n",
    "# Convolutional block\n",
    "conv_blocks = []\n",
    "for sz in filter_sizes:\n",
    "    conv = Convolution1D(filters=num_filters,\n",
    "                         kernel_size=sz,\n",
    "                         padding=\"valid\",\n",
    "                         activation=\"relu\",\n",
    "                         strides=1)(z)\n",
    "    conv = MaxPooling1D(pool_size=2)(conv)\n",
    "    conv = Flatten()(conv)\n",
    "    conv_blocks.append(conv)\n",
    "z = Concatenate()(conv_blocks) if len(conv_blocks) > 1 else conv_blocks[0]\n",
    "\n",
    "z = Dropout(dropout_prob[1])(z)\n",
    "z = Dense(hidden_dims, activation=\"relu\")(z)\n",
    "model_output = Dense(len(labels), activation=\"sigmoid\")(z)\n",
    "\n",
    "model = Model(model_input, model_output)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "# model.compile(loss='categorical_crossentropy', optimizer='rmsprop',metrics=['acc'])\n",
    "model.summary()\n",
    "\n",
    "# Initialize weights with word2vec\n",
    "if model_type == \"CNN-non-static\":\n",
    "    weights = np.array([v for v in embedding_weights.values()])\n",
    "    print(\"Initializing embedding layer with word2vec weights, shape\", weights.shape)\n",
    "    embedding_layer = model.get_layer(\"embedding\")\n",
    "    embedding_layer.set_weights([weights])\n",
    "\n",
    "# Train the model\n",
    "network_hist = model.fit(x_train, y_train, \n",
    "                         batch_size=batch_size, epochs=num_epochs, \n",
    "                         validation_data=(x_test, y_test), verbose=2)\n",
    "\n",
    "score = model.evaluate(x_test, y_test,\n",
    "                       batch_size=batch_size, verbose=1)\n",
    "\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "plot_history(network_hist)\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plot_confusion_matrix(model, classes=labels, title='Confusion matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
