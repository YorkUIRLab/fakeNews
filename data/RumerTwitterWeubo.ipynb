{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Gets text content for tweet IDs\n",
    "'''\n",
    "\n",
    "# standard\n",
    "from __future__ import print_function\n",
    "import getopt\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "# import traceback\n",
    "# third-party: `pip install tweepy`\n",
    "import tweepy\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "sns.set(style='whitegrid', palette='muted', font_scale=1.5)\n",
    "\n",
    "# global logger level is configured in main()\n",
    "Logger = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# batch size depends on Twitter limit, 100 at this time\n",
    "batch_size=100\n",
    "\n",
    "# Generate your own at https://apps.twitter.com/app\n",
    "CONSUMER_KEY = 'FTKEJzQ4N85xCqlLEgxKbQnxV'# 'Consumer Key (API key)'\n",
    "CONSUMER_SECRET = 'eQPjDnxxOZQMNyPDTQSvjinKrmOuS2nQs0DnyLVzeLQJ96yCdb' # 'Consumer Secret (API Secret)'\n",
    "OAUTH_TOKEN = '636585381-69wgslGdJgEjEH9Tw0PXZd3TzPVSogx49LdY2DP2' #'Access Token'\n",
    "OAUTH_TOKEN_SECRET = 'TsG6hHLKjVhVnAYUm5JeWhr4wIyvhlrO6HFUNyfcuvyJZ' # 'Access Token Secret'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to twitter\n",
    "auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "auth.set_access_token(OAUTH_TOKEN, OAUTH_TOKEN_SECRET)\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True)\n",
    "\n",
    "def get_tweet_list(twapi, idlist):\n",
    "    '''\n",
    "    Invokes bulk lookup method.\n",
    "    Raises an exception if rate limit is exceeded.\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    # fetch as little metadata as possible\n",
    "    tweets = []\n",
    "    chunked_ids = list(chunks_ids(idlist, batch_size))\n",
    "    \n",
    "    for ids in chunked_ids: \n",
    "#         print(ids)\n",
    "        tweets.append(twapi.statuses_lookup(id_=ids, include_entities=False, trim_user=True))\n",
    "#     if len(idlist) != len(tweets):\n",
    "#         print('get_tweet_list: unexpected response size %d, expected %d', len(tweets), len(idlist))\n",
    "#     for tweet in tweets:\n",
    "#         print('%s,%s' % (tweet.id, tweet.text.encode('UTF-8')))\n",
    "        \n",
    "    return [item for sublist in tweets for item in sublist]\n",
    "        \n",
    "\n",
    "def chunks_ids(l, n):\n",
    "    # looping till length l\n",
    "    for i in range(0, len(l), n): \n",
    "        yield l[i:i + n]\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Twitter Data (Twitter.txt): This corpus contains 992 labeled events in total. \n",
    "Each line contains one event with the ids of relevant tweets: event_id, label, tweet_ids. \n",
    "For the labels, the value is 1 if the event is a rumor, and is 0 otherwise.\n",
    "Note that we cannot release the specific content of tweets due to the terms of use of Twitter data.\n",
    "Users can download the content themselves via Twitter API. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = []\n",
    "with open('/home/paperspace/sonic/fakeNews/data/rumdect/Twitter.txt') as f:\n",
    "    content = f.readlines()\n",
    "\n",
    "tweeter_stories = []\n",
    "for story in tqdm(content):\n",
    "    story = story.replace('\\t', ' ').split(' ')\n",
    "#     print(len())\n",
    "    ids = story[2:-1]\n",
    "    tweets = get_tweet_list(api, ids)\n",
    "    for tweet in tweets:\n",
    "        tweeter_stories.append({ 'event_id' : story[0], \n",
    "                                'label' : story[1].split(':')[1], \n",
    "                                'tweet_id' : tweet.id, \n",
    "                                'tweet_text' : tweet.text.encode('UTF-8')})\n",
    "#     break\n",
    "\n",
    "df = pd.DataFrame(tweeter_stories)\n",
    "df.to_csv('../data/RumerTwitter.csv', sep='\\t')\n",
    "df['label'].value_counts().plot(kind='bar', alpha=.5)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "(67739, 5)\n",
      "(67739, 5)\n",
      "(67739, 5)\n",
      "(67739, 5)\n",
      "(67739, 5)\n",
      "(67739, 5)\n",
      "(67739, 5)\n",
      "(67739, 5)\n",
      "CPU times: user 8.17 s, sys: 972 ms, total: 9.14 s\n",
      "Wall time: 18.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "tknzr = TweetTokenizer(strip_handles=True, reduce_len=True)\n",
    "\n",
    "def sentence_tokenizer(raw_text):\n",
    "#     return u' '.join([tknzr.tokenize(raw_text)])\n",
    "    return u' '.join([sent.lower().strip() for sent in tknzr.tokenize(raw_text)])\n",
    "\n",
    "def _apply_df(args):\n",
    "    df, func, kwargs = args\n",
    "    print(df.shape)\n",
    "    df['text'] = df['tweet_text'].apply(func, **kwargs)\n",
    "    return df#df.apply(func, **kwargs)\n",
    "\n",
    "def apply_by_multiprocessing(df, func, **kwargs):\n",
    "    workers = kwargs.pop('workers')\n",
    "    pool = multiprocessing.Pool(processes=workers)\n",
    "    result = pool.map(_apply_df, [(d, func, kwargs) for d in np.array_split(df, workers)])\n",
    "    pool.close()\n",
    "    return pd.concat(list(result))\n",
    "\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "print(num_cores) \n",
    "\n",
    "df = pd.read_csv('../data/RumerTwitter.csv', sep='\\t')\n",
    "df = apply_by_multiprocessing(df, sentence_tokenizer,  workers=num_cores)\n",
    "df.to_csv('../data/RumerTwitter.csv', sep='\\t')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    396731\n",
      "1    145181\n",
      "Name: label, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>event_id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>541907</th>\n",
       "      <td>541907</td>\n",
       "      <td>eid:TM1656</td>\n",
       "      <td>0</td>\n",
       "      <td>17868961827</td>\n",
       "      <td>b'RT @Eydeycallme_SK: RT @ToBe757: Smh @ jamar...</td>\n",
       "      <td>b'rt : rt : smh @ jamarcus russell 4 being arr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541908</th>\n",
       "      <td>541908</td>\n",
       "      <td>eid:TM1656</td>\n",
       "      <td>0</td>\n",
       "      <td>17869549120</td>\n",
       "      <td>b'RT @Eydeycallme_SK:Smh @jamarcus russell 4 b...</td>\n",
       "      <td>b'rt : smh russell 4 being arrested for posses...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541909</th>\n",
       "      <td>541909</td>\n",
       "      <td>eid:TM1656</td>\n",
       "      <td>0</td>\n",
       "      <td>17868922195</td>\n",
       "      <td>b'RT @ToBe757: Smh @ jamarcus russell 4 being ...</td>\n",
       "      <td>b'rt : smh @ jamarcus russell 4 being arrested...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541910</th>\n",
       "      <td>541910</td>\n",
       "      <td>eid:TM1656</td>\n",
       "      <td>0</td>\n",
       "      <td>17844350747</td>\n",
       "      <td>b'http://whatisthetrend.net/jamarcus-russell-%...</td>\n",
       "      <td>b'http :/ / whatisthetrend.net/jamarcus-russel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541911</th>\n",
       "      <td>541911</td>\n",
       "      <td>eid:TM1656</td>\n",
       "      <td>0</td>\n",
       "      <td>17838159964</td>\n",
       "      <td>b'RT @followadi: jamarcus russell arrested for...</td>\n",
       "      <td>b'rt : jamarcus russell arrested for possessio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0    event_id  label     tweet_id  \\\n",
       "541907      541907  eid:TM1656      0  17868961827   \n",
       "541908      541908  eid:TM1656      0  17869549120   \n",
       "541909      541909  eid:TM1656      0  17868922195   \n",
       "541910      541910  eid:TM1656      0  17844350747   \n",
       "541911      541911  eid:TM1656      0  17838159964   \n",
       "\n",
       "                                               tweet_text  \\\n",
       "541907  b'RT @Eydeycallme_SK: RT @ToBe757: Smh @ jamar...   \n",
       "541908  b'RT @Eydeycallme_SK:Smh @jamarcus russell 4 b...   \n",
       "541909  b'RT @ToBe757: Smh @ jamarcus russell 4 being ...   \n",
       "541910  b'http://whatisthetrend.net/jamarcus-russell-%...   \n",
       "541911  b'RT @followadi: jamarcus russell arrested for...   \n",
       "\n",
       "                                                     text  \n",
       "541907  b'rt : rt : smh @ jamarcus russell 4 being arr...  \n",
       "541908  b'rt : smh russell 4 being arrested for posses...  \n",
       "541909  b'rt : smh @ jamarcus russell 4 being arrested...  \n",
       "541910  b'http :/ / whatisthetrend.net/jamarcus-russel...  \n",
       "541911  b'rt : jamarcus russell arrested for possessio...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df['label'].value_counts())\n",
    "len(df['tweet_id'].unique())\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# def get_tweet_id(line):\n",
    "#     '''\n",
    "#     Extracts and returns tweet ID from a line in the input.\n",
    "#     '''\n",
    "#     (tagid,_timestamp,_sandyflag) = line.split('\\t')\n",
    "#     (_tag, _search, tweet_id) = tagid.split(':')\n",
    "#     return tweet_id\n",
    "\n",
    "# def get_tweets_single(twapi, idfilepath):\n",
    "#     '''\n",
    "#     Fetches content for tweet IDs in a file one at a time,\n",
    "#     which means a ton of HTTPS requests, so NOT recommended.\n",
    "\n",
    "#     `twapi`: Initialized, authorized API object from Tweepy\n",
    "#     `idfilepath`: Path to file containing IDs\n",
    "#     '''\n",
    "#     # process IDs from the file\n",
    "#     with open(idfilepath, 'rb') as idfile:\n",
    "#         for line in idfile:\n",
    "#             tweet_id = get_tweet_id(line)\n",
    "#             Logger.debug('get_tweets_single: fetching tweet for ID %s', tweet_id)\n",
    "#             try:\n",
    "#                 tweet = twapi.get_status(tweet_id)\n",
    "#                 print('%s,%s' % (tweet_id, tweet.text.encode('UTF-8')))\n",
    "#             except tweepy.TweepError as te:\n",
    "#                 Logger.warn('get_tweets_single: failed to get tweet ID %s: %s', tweet_id, te.message)\n",
    "#                 # traceback.print_exc(file=sys.stderr)\n",
    "#         # for\n",
    "#     # with\n",
    "\n",
    "# def get_tweet_list(twapi, idlist):\n",
    "#     '''\n",
    "#     Invokes bulk lookup method.\n",
    "#     Raises an exception if rate limit is exceeded.\n",
    "#     '''\n",
    "#     # fetch as little metadata as possible\n",
    "#     tweets = twapi.statuses_lookup(id_=idlist, include_entities=False, trim_user=True)\n",
    "#     if len(idlist) != len(tweets):\n",
    "#         Logger.warn('get_tweet_list: unexpected response size %d, expected %d', len(tweets), len(idlist))\n",
    "#     for tweet in tweets:\n",
    "#         print('%s,%s' % (tweet.id, tweet.text.encode('UTF-8')))\n",
    "\n",
    "# def get_tweets_bulk(twapi, idfilepath):\n",
    "#     '''\n",
    "#     Fetches content for tweet IDs in a file using bulk request method,\n",
    "#     which vastly reduces number of HTTPS requests compared to above;\n",
    "#     however, it does not warn about IDs that yield no tweet.\n",
    "\n",
    "#     `twapi`: Initialized, authorized API object from Tweepy\n",
    "#     `idfilepath`: Path to file containing IDs\n",
    "#     '''    \n",
    "#     # process IDs from the file\n",
    "#     tweet_ids = list()\n",
    "#     with open(idfilepath, 'rb') as idfile:\n",
    "#         for line in idfile:\n",
    "#             tweet_id = get_tweet_id(line)\n",
    "#             Logger.debug('Enqueing tweet ID %s', tweet_id)\n",
    "#             tweet_ids.append(tweet_id)\n",
    "#             # API limits batch size\n",
    "#             if len(tweet_ids) == batch_size:\n",
    "#                 Logger.debug('get_tweets_bulk: fetching batch of size %d', batch_size)\n",
    "#                 get_tweet_list(twapi, tweet_ids)\n",
    "#                 tweet_ids = list()\n",
    "#     # process remainder\n",
    "#     if len(tweet_ids) > 0:\n",
    "#         Logger.debug('get_tweets_bulk: fetching last batch of size %d', len(tweet_ids))\n",
    "#         get_tweet_list(twapi, tweet_ids)\n",
    "\n",
    "# def usage():\n",
    "#     print('Usage: get_tweets_by_id.py [options] file')\n",
    "#     print('    -s (single) makes one HTTPS request per tweet ID')\n",
    "#     print('    -v (verbose) enables detailed logging')\n",
    "#     sys.exit()\n",
    "\n",
    "# def main(args):\n",
    "#     logging.basicConfig(level=logging.WARN)\n",
    "#     global Logger\n",
    "#     Logger = logging.getLogger('get_tweets_by_id')\n",
    "#     bulk = True\n",
    "#     try:\n",
    "#         opts, args = getopt.getopt(args, 'sv')\n",
    "#     except getopt.GetoptError:\n",
    "#         usage()\n",
    "#     for opt, _optarg in opts:\n",
    "#         if opt in ('-s'):\n",
    "#             bulk = False\n",
    "#         elif opt in ('-v'):\n",
    "#             Logger.setLevel(logging.DEBUG)\n",
    "#             Logger.debug(\"main: verbose mode on\")\n",
    "#         else:\n",
    "#             usage()\n",
    "#     if len(args) != 1:\n",
    "#         usage()\n",
    "#     idfile = args[0]\n",
    "#     if not os.path.isfile(idfile):\n",
    "#         print('Not found or not a file: %s' % idfile, file=sys.stderr)\n",
    "#         usage()\n",
    "\n",
    "#     # connect to twitter\n",
    "#     auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "#     auth.set_access_token(OAUTH_TOKEN, OAUTH_TOKEN_SECRET)\n",
    "#     api = tweepy.API(auth)\n",
    "\n",
    "#     # hydrate tweet IDs\n",
    "#     if bulk:\n",
    "#         get_tweets_bulk(api, idfile)\n",
    "#     else:\n",
    "#         get_tweets_single(api, idfile)\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     main(sys.argv[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
